import os
import requests
from datetime import datetime

# ä½ çš„ç«™ç‚¹åŸŸå
SITE_URL = "https://www.yourdomain.com"

# æ–‡ç« æ‰€åœ¨ç›®å½•
CONTENT_DIRS = ["./"]

# sitemap æ–‡ä»¶è·¯å¾„
SITEMAP_FILE = "sitemap.xml"

# æ—¥å¿—æ–‡ä»¶
LOG_FILE = "sitemap_update.log"


def log_message(message: str):
    """å†™å…¥æ—¥å¿—æ–‡ä»¶å¹¶æ‰“å°"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}\n"
    print(log_entry.strip())
    with open(LOG_FILE, "a", encoding="utf-8") as log:
        log.write(log_entry)


def generate_sitemap():
    urls = []
    for content_dir in CONTENT_DIRS:
        for root, dirs, files in os.walk(content_dir):
            for file in files:
                if file.endswith(".html"):
                    path = os.path.join(root, file).replace("\\", "/")
                    url = SITE_URL + path.replace("./", "/")
                    lastmod = datetime.fromtimestamp(os.path.getmtime(path)).strftime("%Y-%m-%d")
                    urls.append((url, lastmod))

    sitemap = '<?xml version="1.0" encoding="UTF-8"?>\n'
    sitemap += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'

    for url, lastmod in urls:
        sitemap += "  <url>\n"
        sitemap += f"    <loc>{url}</loc>\n"
        sitemap += f"    <lastmod>{lastmod}</lastmod>\n"
        sitemap += "    <changefreq>weekly</changefreq>\n"
        sitemap += "    <priority>0.8</priority>\n"
        sitemap += "  </url>\n"

    sitemap += "</urlset>"

    with open(SITEMAP_FILE, "w", encoding="utf-8") as f:
        f.write(sitemap)

    log_message(f"âœ… å·²æ›´æ–° {SITEMAP_FILE}ï¼Œå…±æ”¶å½• {len(urls)} ä¸ªé¡µé¢ã€‚")
    return urls


def ping_search_engines():
    sitemap_url = f"{SITE_URL}/{SITEMAP_FILE}"
    search_engines = {
        "Google": f"http://www.google.com/ping?sitemap={sitemap_url}",
        "Bing": f"http://www.bing.com/ping?sitemap={sitemap_url}"
    }

    for name, url in search_engines.items():
        try:
            r = requests.get(url, timeout=10)
            if r.status_code == 200:
                log_message(f"ğŸ“¡ æˆåŠŸé€šçŸ¥ {name}")
            else:
                log_message(f"âš ï¸ é€šçŸ¥ {name} å¤±è´¥ï¼ŒçŠ¶æ€ç  {r.status_code}")
        except Exception as e:
            log_message(f"âŒ æ— æ³•è¿æ¥ {name}: {e}")


if __name__ == "__main__":
    urls = generate_sitemap()
    ping_search_engines()

    # æ‰“å°æ”¶å½•çš„æ–‡ç« åˆ—è¡¨
    log_message("ğŸ“„ æ”¶å½•çš„é¡µé¢åˆ—è¡¨ï¼š")
    for url, lastmod in urls:
        log_message(f"   - {url} (æ›´æ–°äº {lastmod})")

    log_message(f"=== æœ¬æ¬¡æ›´æ–°å®Œæˆï¼Œå…±æ”¶å½• {len(urls)} ç¯‡æ–‡ç«  ===\n")
